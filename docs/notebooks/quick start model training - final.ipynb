{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start Tutorial: Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "In this tutorial you will learn:\n",
    "1. How to design an observation set for your use case\n",
    "2. How to materialize training data\n",
    "3. How your ML training environment can consume training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the prerequisites\n",
    "\n",
    "Learning Objectives\n",
    "\n",
    "In this section you will:\n",
    "* start your local featurebyte server\n",
    "* import libraries\n",
    "* learn the about catalogs\n",
    "* activate a pre-built catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "# library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# load the featurebyte SDK\n",
    "import featurebyte as fb\n",
    "\n",
    "# start the local server, then wait for it to be healthy before proceeding\n",
    "fb.playground()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a pre-built catalog for this tutorial, with the data, metadata, and features already set up\n",
    "\n",
    "Note that creating a pre-built catalog is not a step you will do in real-life. This is a function specific to this quick-start tutorial to quickly skip over many of the preparatory steps and get you to a point where you can materialize features.\n",
    "\n",
    "In a real-life project you would do data modeling, declaring the tables, entities, and the associated metadata. This would not be a frequent task, but forms the basis for best-practice feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "# get the functions to create a pre-built catalog\n",
    "from prebuilt_catalogs import *\n",
    "\n",
    "# create a new catalog for this tutorial\n",
    "catalog = create_tutorial_catalog(PrebuiltCatalog.QuickStartModelTraining)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Create views from tables in the Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "# create the views\n",
    "grocery_customer_view = catalog.get_view(\"GROCERYCUSTOMER\")\n",
    "grocery_invoice_view = catalog.get_view(\"GROCERYINVOICE\")\n",
    "grocery_items_view = catalog.get_view(\"INVOICEITEMS\")\n",
    "grocery_product_view = catalog.get_view(\"GROCERYPRODUCT\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an observation set for your use case\n",
    "\n",
    "Learning Objectives\n",
    "\n",
    "In this section you will learn:\n",
    "* the purpose of observation sets\n",
    "* the relationship between entities, point in time, and observation sets\n",
    "* how to design an observation set suitable for training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study: Predicting Customer Spend\n",
    "\n",
    "Your chain of grocery stores wants to target market customers immediately after each purchase. As one step in this marketing campaign, they want to predict future customer spend in the 14 days after a purchase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept: Materialization\n",
    "\n",
    "A feature in FeatureByte is defined by the logical plan for its computation. The act of computing the feature is known as Feature Materialization.\n",
    "\n",
    "The materialization of features is made on demand to fulfill historical requests, whereas for prediction purposes, feature values are generated through a batch process called a \"Feature Job\". The Feature Job is scheduled based on the defined settings associated with each feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept: Observation set\n",
    "\n",
    "An observation set combines entity key values and historical points-in-time, for which you wish to materialize feature values.\n",
    "\n",
    "The observation set can be a pandas DataFrame or an ObservationTable object representing an observation set in the feature store. An accepted serving name must be used for the column containing the entity values. The column containing points-in-time must be labelled \"POINT_IN_TIME\" and the point-in-time timestamps should be in UTC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept: Point in time\n",
    "\n",
    "A point-in-time for a feature refers to a specific moment in the past with which the feature's values are associated.\n",
    "\n",
    "It is a crucial aspect of historical feature serving, which allows machine learning models to make predictions based on historical data. By providing a point-in-time, a feature can be used to train and test models on past data, enabling them to make accurate predictions for similar situations in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study: Predicting Customer Spend\n",
    "\n",
    "Your chain of grocery stores wants to target market customers immediately after each purchase. As one step in this marketing campaign, they want to predict future customer spend in the 14 days after a purchase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "# get the feature list for the target\n",
    "import json\n",
    "\n",
    "customer_target = catalog.get_target(\"next_customer_sales_14d\")\n",
    "\n",
    "# display details about the target\n",
    "info = customer_target.info()\n",
    "display_info = {\n",
    "    key: info[key] for key in (\"id\", \"target_name\", \"entities\", \"window\", \"primary_table\")\n",
    "}\n",
    "print(json.dumps(display_info, indent=4))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "# create a large observation table from a view\n",
    "\n",
    "# filter the view to exclude points in time that won't have data for historical windows\n",
    "filter = (grocery_invoice_view[\"Timestamp\"] >= pd.to_datetime(\"2022-04-01\")) & (\n",
    "    grocery_invoice_view[\"Timestamp\"] < pd.to_datetime(\"2023-04-01\")\n",
    ")\n",
    "observation_set_view = grocery_invoice_view[filter].copy()\n",
    "\n",
    "# create a new observation table\n",
    "observation_table = observation_set_view.create_observation_table(\n",
    "    name=\"10,000 Customers immediately after each purchase from May-22 to Mar-23\",\n",
    "    sample_rows=10000,\n",
    "    columns=[\"Timestamp\", \"GroceryCustomerGuid\"],\n",
    "    columns_rename_mapping={\n",
    "        \"Timestamp\": \"POINT_IN_TIME\",\n",
    "        \"GroceryCustomerGuid\": \"GROCERYCUSTOMERGUID\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# if the observation table isn't too large, you can materialize it\n",
    "display(observation_table.to_pandas())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Materialize Training Data\n",
    "\n",
    "Learning Objectives\n",
    "\n",
    "In this section you will learn:\n",
    "* how to create a target observation table\n",
    "* how to create historical training data using the target observation table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Get target values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "# Materialize the target\n",
    "training_data_target_table = customer_target.compute_target_table(\n",
    "    observation_table, observation_table_name=\"target_observation_table\"\n",
    ")\n",
    "\n",
    "display(training_data_target_table.to_pandas())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Get historical values with target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "# list the feature lists\n",
    "display(catalog.list_feature_lists())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "# get the feature list\n",
    "feature_list = catalog.get_feature_list(\"Features\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "# Compute the historical feature table by passing in the observation table that contains the target values\n",
    "training_table_features = feature_list.compute_historical_feature_table(\n",
    "    training_data_target_table,\n",
    "    historical_feature_table_name=\"customer training table - invoices Apr-22 to Mar-23 - features only\",\n",
    ")\n",
    "\n",
    "# display the training data\n",
    "training_data = training_table_features.to_pandas()\n",
    "display(training_data)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consuming training data\n",
    "\n",
    "Learning Objectives\n",
    "\n",
    "In this section you will learn:\n",
    "* how to save a training file\n",
    "* how to use a pandas data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Save the training data to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "# save training data as a csv file\n",
    "training_data.to_csv(\"training_data.csv\", index=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "# save the training file as a parquet file\n",
    "training_data.to_parquet(\"training_data.parquet\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Training a scikit learn model\n",
    "\n",
    "Note that you will need to install scikit learn https://scikit-learn.org/stable/install.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "# EDA on the training data\n",
    "training_data.describe()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "source": [
    "# do any columns in the training data contain missing values?\n",
    "training_data.isna().any()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "! pip install scikit-learn"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "source": [
    "# use sklearn to train a random forest regression model on the training data\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    training_data.drop(columns=[\"GROCERYCUSTOMERGUID\", \"POINT_IN_TIME\"]),\n",
    "    training_data[\"next_customer_sales_14d\"],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# train the model\n",
    "model = HistGradientBoostingRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# get predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# calculate the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean squared error: \", mse)\n",
    "\n",
    "# save the model\n",
    "import joblib\n",
    "\n",
    "joblib.dump(model, \"model.pkl\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you've completed the quick-start feature engineering tutorial, you can put your knowledge into practice or learn more:<br>\n",
    "1. Learn more about materializing features via the \"Deep Dive Materializing Features\" tutorial\n",
    "2. Put your knowledge into practice by creating features in the \"credit card dataset feature engineering playground\" or \"healthcare dataset feature engineering playground\" workspaces\n",
    "3. Learn more about feature governance via the \"Quick Start Feature Governance\" tutorial"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
