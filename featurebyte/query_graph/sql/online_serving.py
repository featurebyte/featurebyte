"""
SQL generation for online serving
"""
from __future__ import annotations

from typing import Any, Optional, Tuple, cast

import hashlib
import json
from collections import defaultdict
from dataclasses import dataclass

from bson import ObjectId
from sqlglot import expressions, parse_one
from sqlglot.expressions import Expression, Identifier, Table, select

from featurebyte.enum import InternalName, SourceType, SpecialColumnName
from featurebyte.models.base import FeatureByteBaseModel
from featurebyte.query_graph.enum import NodeOutputType, NodeType
from featurebyte.query_graph.graph import QueryGraph
from featurebyte.query_graph.node import Node
from featurebyte.query_graph.node.generic import AliasNode, ProjectNode
from featurebyte.query_graph.sql.adapter import BaseAdapter, get_sql_adapter
from featurebyte.query_graph.sql.common import REQUEST_TABLE_NAME, quoted_identifier, sql_to_string
from featurebyte.query_graph.sql.feature_compute import FeatureExecutionPlanner
from featurebyte.query_graph.sql.specs import TileBasedAggregationSpec
from featurebyte.query_graph.sql.tile_util import (
    calculate_first_and_last_tile_indices,
    update_maximum_window_size_dict,
)
from featurebyte.query_graph.transform.operation_structure import OperationStructureExtractor


class OnlineStorePrecomputeQuery(FeatureByteBaseModel):
    """
    Represents a query required to support pre-computation for a feature

    sql: str
        Sql query that performs pre-computation for a feature. The result is not the feature values
        directly but intermediate results before post-aggregation transforms.
    tile_id: str
        Tile table identifier
    aggregation_id: str
        Aggregation identifier (identifies columns in the tile table)
    table_name: str
        Online store table name to store the pre-computed result
    result_name: str
        Column name generated by sql to be stored in online store table
    result_type: str
        Type of the colum generated by sql
    """

    sql: str
    tile_id: str
    aggregation_id: str
    table_name: str
    result_name: str
    result_type: str
    serving_names: list[str]


@dataclass
class OnlineStoreUniverse:
    """
    Represents a query that produces the "universe" of online store - the unique set of entities for
    a simple feature (derived from a single tile table) as at a point in time.

    It is derived based on the feature (e.g. a feature with larger window size will have a larger
    set of universe) and the underlying data (whether there are any events that occurred within the
    feature window as at a particular point in time).
    """

    expr: expressions.Select
    columns: list[str]


class OnlineStorePrecomputePlan:
    """
    OnlineStorePrecomputePlan is responsible for extracting universe for online store feature
    pre-computation

    Parameters
    ----------
    graph: QueryGraph
        Query graph
    node: Node
        Query graph node
    adapter: BaseAdapter
        Instance of BaseAdapter for engine specific sql generation
    """

    def __init__(self, graph: QueryGraph, node: Node, adapter: BaseAdapter):
        self.adapter = adapter
        self.max_window_size_by_tile_id: dict[str, Optional[int]] = {}
        self.params_by_tile_id: dict[str, Any] = {}
        self.params_by_agg_result_name: dict[str, Any] = {}
        self._update(graph, node)

    def construct_online_store_precompute_queries(
        self, source_type: SourceType
    ) -> list[OnlineStorePrecomputeQuery]:
        """
        Construct SQL queries for online store pre-computation

        Returns
        -------
        list[OnlineStorePrecomputeQuery]
        """
        result = []
        for agg_result_name, agg_params in self.params_by_agg_result_name.items():
            tile_id = agg_params["tile_id"]
            universe = self._construct_online_store_universe(tile_id)
            query = self._construct_online_store_precompute_query(
                graph=agg_params["pruned_graph"],
                node=agg_params["pruned_node"],
                tile_id=agg_params["tile_id"],
                aggregation_id=agg_params["aggregation_id"],
                agg_result_name=agg_result_name,
                universe=universe,
                source_type=source_type,
            )
            result.append(query)
        return result

    def _get_first_and_last_indices(self, tile_id: str) -> Tuple[Optional[Expression], Expression]:
        """
        Get the first and last tile indices required to compute the feature

        Returns
        -------
        Tuple[Optional[Expression], Expression]
        """
        params_dict = self.params_by_tile_id[tile_id]
        point_in_time_expr = self._get_point_in_time_expr()
        window_size = self.max_window_size_by_tile_id[tile_id]
        first_index, last_index = calculate_first_and_last_tile_indices(
            adapter=self.adapter,
            point_in_time_expr=point_in_time_expr,
            window_size=window_size,
            frequency=params_dict["frequency"],
            time_modulo_frequency=params_dict["time_modulo_frequency"],
        )
        return first_index, last_index

    def _construct_online_store_precompute_query(
        self,
        graph: QueryGraph,
        node: Node,
        tile_id: str,
        aggregation_id: str,
        agg_result_name: str,
        universe: OnlineStoreUniverse,
        source_type: SourceType,
    ) -> OnlineStorePrecomputeQuery:

        planner = FeatureExecutionPlanner(graph, source_type=source_type, is_online_serving=False)
        plan = planner.generate_plan([node])

        sql_expr = plan.construct_combined_sql(
            request_table_name=REQUEST_TABLE_NAME,
            point_in_time_column=SpecialColumnName.POINT_IN_TIME,
            request_table_columns=universe.columns,
            prior_cte_statements=[(REQUEST_TABLE_NAME, universe.expr)],
            exclude_post_aggregation=True,
        )
        sql = sql_to_string(sql_expr, source_type)
        entity_ids, serving_names = get_entities_ids_and_serving_names(graph, node)
        table_name = get_online_store_table_name_from_entity_ids(entity_ids)

        op_struct = (
            OperationStructureExtractor(graph=graph)
            .extract(node=node)
            .operation_structure_map[node.name]
        )
        assert len(op_struct.aggregations) == 1
        aggregation = op_struct.aggregations[0]
        result_type = self.adapter.get_physical_type_from_dtype(aggregation.dtype)

        return OnlineStorePrecomputeQuery(
            sql=sql,
            tile_id=tile_id,
            aggregation_id=aggregation_id,
            table_name=table_name,
            result_name=agg_result_name,
            result_type=result_type,
            serving_names=sorted(serving_names),
        )

    def _construct_online_store_universe(self, tile_id: str) -> OnlineStoreUniverse:
        """
        Construct SQL expression that extracts the universe for online store. The result of this SQL
        contains a point in time column, so it can be used directly as the request table.

        Parameters
        ----------
        tile_id: str
            Tile table identifier

        Returns
        -------
        OnlineStoreUniverse
        """
        first_index, last_index = self._get_first_and_last_indices(tile_id)

        params = self.params_by_tile_id[tile_id]
        serving_names = params["serving_names"]
        keys = params["keys"]

        filter_conditions: list[Expression] = []
        if first_index is not None:
            filter_conditions.append(expressions.GTE(this="INDEX", expression=first_index))
        filter_conditions.append(expressions.LT(this="INDEX", expression=last_index))

        expr = (
            select(
                expressions.alias_(self._get_point_in_time_expr(), SpecialColumnName.POINT_IN_TIME),
                *[
                    expressions.alias_(
                        quoted_identifier(key_col), quoted_identifier(serving_name_col)
                    )
                    for key_col, serving_name_col in zip(keys, serving_names)
                ],
            )
            .distinct()
            .from_(tile_id)
            .where(expressions.and_(*filter_conditions))
        )
        universe_columns = [SpecialColumnName.POINT_IN_TIME] + serving_names

        return OnlineStoreUniverse(expr=expr, columns=universe_columns)

    def _update(self, graph: QueryGraph, node: Node) -> None:
        """
        Update state given a query graph node

        Parameters
        ----------
        graph: QueryGraph
            Query graph
        node: Node
            Query graph node
        """
        groupby_nodes = list(graph.iterate_nodes(node, NodeType.GROUPBY))
        for groupby_node in groupby_nodes:
            agg_specs = TileBasedAggregationSpec.from_groupby_query_node(groupby_node, self.adapter)
            agg_id = agg_specs[0].aggregation_id
            tile_id = agg_specs[0].tile_table_id
            for agg_spec in agg_specs:
                update_maximum_window_size_dict(
                    max_window_size_dict=self.max_window_size_by_tile_id,
                    key=tile_id,
                    window_size=agg_spec.window,
                )
                self.params_by_tile_id[tile_id] = {
                    "keys": agg_spec.keys,
                    "serving_names": agg_spec.serving_names,
                    "frequency": agg_spec.frequency,
                    "time_modulo_frequency": agg_spec.time_modulo_frequency,
                }
                project_node = graph.add_operation(
                    NodeType.PROJECT,
                    node_params={"columns": [agg_spec.feature_name]},
                    node_output_type=NodeOutputType.SERIES,
                    input_nodes=[groupby_node],
                )
                pruned_graph, node_name_map = graph.prune(project_node, aggressive=True)
                pruned_node = pruned_graph.get_node_by_name(node_name_map[project_node.name])
                self.params_by_agg_result_name[agg_spec.agg_result_name] = {
                    "tile_id": tile_id,
                    "pruned_graph": pruned_graph,
                    "pruned_node": pruned_node,
                    "aggregation_id": agg_id,
                }

    @classmethod
    def _get_point_in_time_expr(cls) -> Expression:
        return cast(
            Expression,
            parse_one(f"CAST({InternalName.POINT_IN_TIME_SQL_PLACEHOLDER} AS TIMESTAMP)"),
        )


def get_online_store_precompute_queries(
    graph: QueryGraph,
    node: Node,
    source_type: SourceType,
) -> list[OnlineStorePrecomputeQuery]:
    """
    Construct the SQL code that can be scheduled for online store feature pre-computation

    Parameters
    ----------
    graph : QueryGraph
        Query graph
    node : Node
        Query graph node
    source_type : SourceType
        Source type information

    Returns
    -------
    str
    """
    universe_plan = OnlineStorePrecomputePlan(graph, node, adapter=get_sql_adapter(source_type))
    queries = universe_plan.construct_online_store_precompute_queries(source_type=source_type)
    return queries


def get_entities_ids_and_serving_names(
    graph: QueryGraph, node: Node
) -> Tuple[set[ObjectId], set[str]]:
    """
    Get the union of all entity ids of the node's input nodes. Only point in time groupby nodes are
    considered, since other nodes that produce features (e.g. ItemGroupyNode) generate features that
    cannot be pre-computed.

    Parameters
    ----------
    graph : QueryGraph
        Query graph
    node : Node
        Query graph node

    Returns
    -------
    Tuple[set[ObjectId], set[str]]
    """
    entity_ids = set()
    serving_names = set()
    for groupby_node in graph.iterate_nodes(node, NodeType.GROUPBY):
        parameters = groupby_node.parameters.dict()
        entity_ids.update(parameters["entity_ids"])
        serving_names.update(parameters["serving_names"])
    return entity_ids, serving_names


def get_online_store_table_name_from_entity_ids(entity_ids_set: set[ObjectId]) -> str:
    """
    Get the online store table name given the entity ids

    Parameters
    ----------
    entity_ids_set : set[ObjectId]
        Entity ids

    Returns
    -------
    str
    """
    hasher = hashlib.shake_128()
    hasher.update(json.dumps(sorted(map(str, entity_ids_set))).encode("utf-8"))
    identifier = hasher.hexdigest(20)
    online_store_table_name = f"online_store_{identifier}"
    return online_store_table_name


def get_online_store_table_name_from_graph(graph: QueryGraph, node: Node) -> str:
    """
    Get the online store table given the query graph and node

    Parameters
    ----------
    graph : QueryGraph
        Query graph
    node : Node
        Query graph node

    Returns
    -------
    str
    """
    entity_ids, _ = get_entities_ids_and_serving_names(graph, node)
    return get_online_store_table_name_from_entity_ids(entity_ids)


def is_online_store_eligible(graph: QueryGraph, node: Node) -> bool:
    """
    Check whether the feature represented by the given node is eligible for online store lookup

    Parameters
    ----------
    graph : QueryGraph
        Query graph
    node : Node
        Query graph node

    Returns
    -------
    bool
    """
    op_struct = graph.extract_operation_structure(node)
    if not op_struct.is_time_based:
        return False
    has_point_in_time_groupby = False
    for _ in graph.iterate_nodes(node, NodeType.GROUPBY):
        has_point_in_time_groupby = True
    return has_point_in_time_groupby


@dataclass
class OnlineStoreLookupSpec:
    """
    OnlineStoreLookupSpec represents a feature that can be looked up from the online store
    """

    feature_name: str
    feature_store_table_name: str
    serving_names: list[str]

    @classmethod
    def from_graph_and_node(cls, graph: QueryGraph, node: Node) -> OnlineStoreLookupSpec:
        """
        Create an OnlineStoreLookupSpec from query graph node associated with a Feature

        Parameters
        ----------
        graph: QueryGraph
            Query graph
        node: Node
            Query graph node

        Returns
        -------
        OnlineStoreLookupSpec
        """
        entity_ids_set, serving_names_set = get_entities_ids_and_serving_names(graph, node)
        feature_store_table_name = get_online_store_table_name_from_entity_ids(entity_ids_set)

        # node should be associated with a Feature, so it must be either a ProjectNode or an
        # AliasNode
        assert isinstance(node, (ProjectNode, AliasNode))
        if isinstance(node, ProjectNode):
            feature_name = cast(str, node.parameters.columns[0])
        else:
            # node is an AliasNode
            feature_name = cast(str, node.parameters.name)

        spec = OnlineStoreLookupSpec(
            feature_name=feature_name,
            feature_store_table_name=feature_store_table_name,
            serving_names=sorted(serving_names_set),
        )
        return spec


class OnlineStoreRetrievePlan:
    """
    OnlineStoreRetrievePlan is responsible for generating SQL for feature lookup from online store
    """

    def __init__(self, graph: QueryGraph):
        self.graph = graph

        # Mapping from online store table name to OnlineStoreLookupSpec list
        self.online_store_specs: dict[str, list[OnlineStoreLookupSpec]] = defaultdict(list)

        # List of feature names in the order they are provided
        self.feature_names: list[str] = []

    def update_if_eligible(self, node: Node) -> bool:
        """
        Check if the node is eligible for online store lookup and if so update state

        Parameters
        ----------
        node: Node
            Query graph node

        Returns
        -------
        bool
        """
        if not is_online_store_eligible(self.graph, node):
            return False

        spec = OnlineStoreLookupSpec.from_graph_and_node(self.graph, node)
        self.online_store_specs[spec.feature_store_table_name].append(spec)
        self.feature_names.append(spec.feature_name)
        return True

    def construct_retrieval_sql(
        self,
        request_table_columns: list[str],
        request_table_name: Optional[str] = None,
        request_table_expr: Optional[expressions.Select] = None,
    ) -> expressions.Select:
        """
        Construct SQL expression to lookup feature from online store

        Parameters
        ----------
        request_table_columns: list[str]
            Columns in the request table
        request_table_name: Optional[str]
            Name of the request table
        request_table_expr: Optional[expressions.Select]
            Select statement that constructs the request table

        Returns
        -------
        expressions.Select
        """
        # Original columns
        expr = select(*[f"REQ.{quoted_identifier(col).sql()}" for col in request_table_columns])

        if request_table_name is not None:
            expr = expr.from_(
                expressions.alias_(quoted_identifier(request_table_name), alias="REQ")
            )
        else:
            assert request_table_expr is not None
            expr = expr.from_(request_table_expr.subquery(alias="REQ"))

        # Perform one left join for each unique online store table and retrieve one or more
        # pre-computed features
        qualified_feature_names = {}
        for index, (feature_store_table_name, specs) in enumerate(self.online_store_specs.items()):
            serving_names = specs[0].serving_names
            feature_names = [spec.feature_name for spec in specs]
            join_alias = f"T{index}"
            join_conditions = expressions.and_(
                *[
                    f"REQ.{quoted_identifier(name).sql()} = {join_alias}.{quoted_identifier(name).sql()}"
                    for name in serving_names
                ]
            )
            for feature_name in feature_names:
                qualified_feature_names[
                    feature_name
                ] = f"{join_alias}.{quoted_identifier(feature_name).sql()}"
            expr = expr.join(
                Table(this=Identifier(this=feature_store_table_name)),
                join_alias=join_alias,
                on=join_conditions,
                join_type="left",
            )

        # Select the joined features in their original order
        expr = expr.select(
            *[qualified_feature_names[feature_name] for feature_name in self.feature_names]
        )
        return expr


def construct_feature_sql_with_enriched_request_table(
    expr: expressions.Select,
    graph: QueryGraph,
    online_excluded_nodes: list[Node],
    request_table_name: str,
    enriched_request_table_columns: list[str],
    source_type: SourceType,
) -> expressions.Select:
    """
    Construct SQL expression to compute features on demand for features that are cannot be
    pre-computed in online store (e.g. non-time aware aggregation, SCD lookup,etc)

    Parameters
    ----------
    expr: Select
        Expression with the request table with features added from online store
    graph: QueryGraph
        Query graph
    online_excluded_nodes: list[Node]
        List of nodes corresponding to features not ava
    request_table_name: str
        Original request table name
    enriched_request_table_columns: list[str]
        Columns in the updated request table (original request table columns and features looked up
        from online store)
    source_type: SourceType
        Source type information

    Returns
    -------
    Select
    """
    planner = FeatureExecutionPlanner(graph, source_type=source_type, is_online_serving=True)
    plan = planner.generate_plan(online_excluded_nodes)

    new_request_table_expr = expr.select(f"SYSDATE() AS {SpecialColumnName.POINT_IN_TIME}")
    new_request_table_name = request_table_name + "_POST_FEATURE_STORE_LOOKUP"
    ctes = [(new_request_table_name, new_request_table_expr)]

    expr = plan.construct_combined_sql(
        request_table_name=new_request_table_name,
        point_in_time_column=SpecialColumnName.POINT_IN_TIME,
        request_table_columns=enriched_request_table_columns,
        prior_cte_statements=ctes,
    )
    return expr


def get_online_store_retrieval_sql(
    graph: QueryGraph,
    nodes: list[Node],
    source_type: SourceType,
    request_table_columns: list[str],
    request_table_name: Optional[str] = None,
    request_table_expr: Optional[expressions.Select] = None,
) -> str:
    """
    Construct SQL code that can be used to lookup pre-computed features from online store

    Parameters
    ----------
    graph: QueryGraph
        Query graph
    nodes: list[Node]
        List of query graph nodes
    source_type: SourceType
        Source type information
    request_table_columns: list[str]
        Request table columns
    request_table_name: Optional[str]
        Name of the request table
    request_table_expr: Optional[expressions.Select]
        Select statement for the request table

    Returns
    -------
    str
    """
    online_store_plan = OnlineStoreRetrievePlan(graph)
    online_excluded_nodes = []

    for node in nodes:
        if not online_store_plan.update_if_eligible(node):
            online_excluded_nodes.append(node)

    expr = online_store_plan.construct_retrieval_sql(
        request_table_columns=request_table_columns,
        request_table_expr=request_table_expr,
        request_table_name=request_table_name,
    )

    if online_excluded_nodes:
        enriched_request_table_columns = request_table_columns + online_store_plan.feature_names
        if request_table_name is None:
            request_table_name = REQUEST_TABLE_NAME
        expr = construct_feature_sql_with_enriched_request_table(
            expr=expr,
            graph=graph,
            online_excluded_nodes=online_excluded_nodes,
            request_table_name=request_table_name,
            enriched_request_table_columns=enriched_request_table_columns,
            source_type=source_type,
        )

    return sql_to_string(expr, source_type=source_type)
