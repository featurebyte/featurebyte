version: '3'

tasks:
  init:
    desc: "Initialize the project for development"
    preconditions:
      - sh: poetry --version
        msg: "Poetry is not installed. Please install it from https://python-poetry.org/docs/#installation"
      - sh: docker --version
        msg: "Docker is not installed. Please install it from https://docs.docker.com/get-docker/"
      - sh: yq --version
        msg: "yq is not installed. Please install it from https://github.com/mikefarah/yq"
      - sh: jq --version
        msg: "jq is not installed. Please install it from https://stedolan.github.io/jq/download/"
    deps:
      - task: install
    cmds:
      - poetry run pre-commit install

  install:
    desc: "Install the project dependencies"
    sources:
      - pyproject.toml
      - poetry.lock
    deps:
      - task: build-jar
    cmds:
      - poetry install -n --sync --extras=server

  lint-java:
    desc: "Run linter for java"
    sources:
      - hive-udf/**/*
    cmds:
        - cd hive-udf && ./gradlew spotlessCheck

  format-java:
    desc: "Format the java code"
    sources:
      - hive-udf/**/*
    cmds:
      - cd hive-udf && ./gradlew spotlessApply

  test-java:
    desc: "Run the java tests"
    sources:
      - hive-udf/**/*
    cmds:
      - cd hive-udf && ./gradlew test

  build-jar:
    desc: "Compile the hive jar files"
    run: once
    sources:
      - hive-udf/**/*
    deps:
      - task: lint-java
    cmds:
      - cd hive-udf && ./gradlew shadowJar
      - task: test-java
      - rm -f featurebyte/sql/spark/*.jar
      - cp hive-udf/lib/build/libs/*.jar featurebyte/sql/spark/

  format:
    desc: "Format the code"
    sources:
      - featurebyte/**/*
      - tests/**/*
      - poetry.lock
      - pyproject.toml
    deps:
      - task: install
    cmds:
      - poetry run pyupgrade --py38-plus **/*.py
      - poetry run isort .
      - poetry run black .
      - poetry run toml-sort --all --in-place pyproject.toml poetry.lock

  lint:
    desc: "Run the linter"
    deps:
      - task: install
    cmds:
      - task: lint-style
      - task: lint-type
      - task: lint-safety
      - task: lint-bandit

  lint-style:
    desc: "Run the linter[style]"
    vars:
      PYLINT_DISABLE_FOR_SRCS: 'too-few-public-methods'
      PYLINT_DISABLE_FOR_TESTS: 'redefined-outer-name,invalid-name,protected-access,too-few-public-methods,unspecified-encoding,duplicate-code'
      DARG_SOURCES:
        sh: |
          echo "$(find featurebyte -type d \( -path featurebyte/routes \) -prune -false -o -name "*.py" ! -path "featurebyte/__main__.py" ! -path "featurebyte/datasets/*" ! -path "featurebyte/conftest.py" | xargs)" "$(find featurebyte -type f \( -path featurebyte/routes \) -o -name "controller.py" | xargs)"
    sources:
      - poetry.lock
      - pyproject.toml
      - featurebyte/**/*
      - tests/**/*
    cmds:
      - poetry run toml-sort --check poetry.lock pyproject.toml    # Check if user been using pre-commit hook
      - poetry run isort --diff --check-only --settings-path pyproject.toml .
      - poetry run black --diff --check .
      - poetry run pylint --disable={{ .PYLINT_DISABLE_FOR_SRCS }} --rcfile pyproject.toml featurebyte
      - poetry run pylint --disable={{ .PYLINT_DISABLE_FOR_TESTS }} --rcfile pyproject.toml tests
      - poetry run darglint --verbosity 2 {{ .DARG_SOURCES }}

  lint-type:
    desc: "Run the linter[type]"
    sources:
      - poetry.lock
      - pyproject.toml
      - featurebyte/**/*
      - tests/**/*
    cmds:
      - cmd: if [ ! -d .mypy_cache ]; then mkdir .mypy_cache; fi
        silent: true
      - poetry run mypy --install-types --non-interactive --config-file pyproject.toml --exclude '(featurebyte/conftest.py)' .

  lint-safety:
    desc: "Run the linter[safety]"
    vars:
      PERMISSIVE_LICENSES: >
        Apache License 2.0;
        Apache License, Version 2.0;
        Apache Software License;
        BSD;
        BSD License;
        Historical Permission Notice and Disclaimer (HPND);
        GNU General Public License v2 (GPLv2);
        ISC License (ISCL);
        ISC;
        MIT License;
        MIT;
        MPL-2.0;
        Mozilla Public License 2.0 (MPL 2.0);
        Public Domain;
        Python Software Foundation License;
        The Unlicense (Unlicense)
      PACKAGES:
        sh: poetry export --without-hashes --without-urls --extras server | cut -d '=' -f1 | xargs
    sources:
      - poetry.lock
      - pyproject.toml
      - featurebyte/**/*
    cmds:
      - poetry run pip-licenses --packages '{{ .PACKAGES }}' --allow-only='{{ .PERMISSIVE_LICENSES }}'
      - poetry run pip-audit

  lint-bandit:
    desc: "Run the linter[bandit]"
    sources:
      - poetry.lock
      - pyproject.toml
      - featurebyte/**/*
    cmds:
      - poetry run bandit -c pyproject.toml -ll --recursive featurebyte

  test:
    desc: Runs full test-suite
    deps:
      - task: install
    cmds:
      - task: test-unit
      - task: test-integration
      - task: test-docs

  test-unit:
    desc: Runs unit tests
    deps:
      - task: install
    sources:
      - poetry.lock
      - pyproject.toml
      - featurebyte/**/*
      - tests/**/*
    cmds:
      - poetry run pytest --timeout=240 --junitxml=pytest.xml.0 -n auto --cov=featurebyte tests/unit

  test-integration:
    desc: Runs integration tests
    deps:
      - task: install
    cmds:
      - task: test-integration-snowflake
      - task: test-integration-spark
      - task: test-integration-databricks

  test-integration-snowflake:
    desc: Runs integration tests against Snowflake
    deps:
      - task: install
    cmds:
      - task: test-setup
      - poetry run pytest --timeout=240 --junitxml=pytest.xml.1 -n auto --cov=featurebyte tests/integration --source-types none,snowflake
      - task: test-teardown

  test-integration-spark:
    desc: Runs integration tests against Spark
    deps:
      - task: install
    cmds:
      - task: test-setup
      - poetry run pytest --timeout=240 --junitxml=pytest.xml.2 --cov=featurebyte tests/integration --source-types spark --maxfail=1
      - task: test-teardown

  test-integration-databricks:
    desc: Runs integration tests against Databricks
    deps:
      - task: install
    cmds:
      - task: test-setup
      - poetry run pytest --timeout=900 --junitxml=pytest.xml.3 --cov=featurebyte tests/integration --source-types databricks --maxfail=1
      - task: test-teardown

  test-docs:
    desc: Runs documentation tests
    sources:
      - featurebyte/**/*
    deps:
      - task: install
    cmds:
      - task: test-docs-setup
      - poetry run pytest --timeout=240 featurebyte
      - task: test-docs-teardown

  test-docs-setup:
    desc: "Setup the test environment for docs"
    deps:
      - task: docker-build
    cmds:
      - poetry run python scripts/test-docs-setup.py

  test-docs-teardown:
    desc: "Teardown the test environment for docs"
    cmds:
      - poetry run featurebyte stop

  test-merge:
    desc: Runs tests on merge
    cmds:
      - "echo 'coverage: platform' > pytest-coverage.txt"
      - poetry run coverage combine
      - poetry run coverage report >> pytest-coverage.txt
      - poetry run junitparser merge pytest.xml.* pytest.xml

  test-setup:
    desc: "Setup the test environment"
    env:
      LOCAL_UID:
        sh: id -u
      LOCAL_GID:
        sh: id -g
    cmds:
      - mkdir -p ~/.spark/data
      - cd docker && docker compose -p featurebyte-test -f docker-compose.yml up -d
      - task: test-setup-status

  test-setup-status:
    desc: "Wait for the test environment to be ready"
    internal: true
    preconditions:
      - sh: docker compose ls | grep 'featurebyte-test'
        msg: "Test environment is not running."
    cmds:
      -  |
        for i in {1..60}; do
          docker container inspect -f "{{"{{"}} .State.Health.Status {{"}}"}}" spark-thrift-test | grep 'healthy' -q && exit 0
          sleep 1
        done
        exit 1

  test-teardown:
    desc: "Teardown the test environment"
    preconditions:
      - sh: docker compose ls | grep 'featurebyte-test'
        msg: "Test environment is not running."
    cmds:
      - cd docker && docker compose -p featurebyte-test -f docker-compose.yml down

  docs:
    desc: "Build the documentation and reload the browser"
    deps:
      - task: install
    env:
      PYTHONPATH:
        sh: echo "$(pwd)/docs/extensions"
      FB_DOCS_DEBUG_MODE: True
    cmds:
      - poetry run mkdocs serve --config-file mkdocs.yaml

  docs-persist-reference:
    desc: "Build the documentation and persist the docs locally."
    deps:
      - task: install
    env:
      PYTHONPATH:
        sh: echo "$(pwd)/docs/extensions"
    cmds:
      - poetry run mkdocs build --config-file mkdocs.yaml

  docs-dump-csv:
    desc: "Dump the documentation into a CSV file for easy browsing."
    deps:
      - task: install
    env:
      PYTHONPATH:
        sh: echo "$(pwd)/docs/extensions"

    cmds:
      - poetry run python featurebyte/common/documentation/extract_csv.py

  docker-build:
    desc: "Build the docker image"
    deps:
      - task: install
    cmds:
      - docker buildx build . -f docker/Dockerfile -t featurebyte-server:latest

  docker-dev:
    desc: "Starts featurebyte-server in development mode"
    deps:
      - task: install
    cmds:
      - task: docker-build
      - poetry run featurebyte start --local
      - poetry run featurebyte start spark --local

  docker-dev-stop:
    desc: "Stops featurebyte-server in development mode"
    cmds:
      - poetry run featurebyte stop

  docker-clean:
    desc: "Clean the docker images and data directories"
    ignore_error: true
    cmds:
      - docker volume rm $(docker volume ls -q)
      - rm -rf ~/.spark
      - rm -rf ~/.featurebyte/data

  publish-mongodb:
    desc: "Publish mongodb package to public featurebyte registry"
    dir: docker/
    cmds:
      - docker buildx build --platform linux/amd64,linux/arm64 -t featurebyte/mongo:latest -t featurebyte/mongo:6 -f mongo.Dockerfile . --push
